= {app-name}
:favicon: images/favicon.svg
:app-name: RIOT File
:app: riot-file
:resources: ../connectors/file/src/test/resources
:toc: left
:numbered:
:toclevels: 2
:toc-title: Contents
:source-highlighter: coderay
:icons: font
:imagesdir: images
:linkattrs:
:sectanchors:
:docinfo: shared-head,private-head
ifdef::env-github[]
:caution-caption: :fire:
:important-caption: :heavy_exclamation_mark:
:note-caption: :information_source:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]

== Overview

*{app-name}* lets you import/export local or remote files in many formats like CSV, fixed-width, JSON, and XML.

include::getting_started.adoc[]

== Import

Use the `import` command to import data from files in CSV, fixed-width, JSON, and XML formats.

=== Redis Commands

include::import.adoc[]


=== File Paths
Paths can include https://man7.org/linux/man-pages/man7/glob.7.html[wildcard patterns].

{app-name} will try to determine the file type from its extension (e.g. `.csv` or `.json`), but you can specify it explicity using the `--filetype` option. Gzipped files are supported and the extension before `.gz` is used (e.g. `myfile.json.gz` -> JSON type). 

.Examples
* `/path/file.csv`
* `/path/file-*.csv`
* `/path/file.json`
* `\http://data.com/file.csv`
* `\http://data.com/file.json.gz`

TIP: Use `-` to read from standard input.

For AWS S3 buckets you can specify access and secret keys as well as the region for the bucket.

`{app} import s3://my-bucket/path/file.json --s3-region us-west-1 --s3-access xxxxxx --s3-secret xxxxxx`

For Google Cloud Storage you can specify credentials and project id for the bucket:

`{app} import gs://my-bucket/path/file.json --gcs-key-file key.json --gcs-project-id my-gcp-project`


=== Flat Files

{app-name} supports delimited (CSV) and fixed-length (aka fixed-width) formats.

If the file has a header containing field names use the `--header` option. Otherwise specify the field names explicitly using the `--fields` option. 

==== Delimited

The default delimiter character is comma (`,`). It can be changed with the `--delimiter` option.

Let's consider this CSV file:

.https://raw.githubusercontent.com/nickhould/craft-beers-dataset/master/data/processed/beers.csv[beers.csv]
|=========
|   | abv   | ibu | id   | name        | style                   | brewery_id | ounces

| 0 | 0.05  |     | 1436 | Pub Beer    | Pale Lager     | 408        | 12.0

| 1 | 0.066 |     | 2265 | Devil's Cup | APA | 177        | 12.0

| ... | | | | | | |

|=========

The following command imports that CSV file into Redis as hashes using `beer` as the key prefix and `id` as primary key.

.CSV import example
[source,shell]
----
include::{resources}/csv/import-hmset.txt[]
----

This creates hashes with keys `beer:1436`, `beer:2265`, ...


.CSV import to geo set
[source,shell]
----
include::{resources}/csv/import-geoadd.txt[]
----


==== Fixed-Length

These files have fixed-width fields. The width of each field must be defined using the `--ranges` option.

=== JSON

The expected format for JSON files is:

[source,json]
----
[
  {
    ...
  },
  {
    ...
  }
]
----

.JSON import example
[source,shell]
----
include::{resources}/json/import-hmset.txt[]
----

JSON records are trees with potentially nested values that need to be flattened when the target is a Redis hash for example.

To that end, {app-name} uses a field naming convention to flatten JSON objects and arrays:

.Nested object
[source,json]
----
{
  "field":
    {
      "sub": "value"
    }
}
----

->

----
field.sub=value`
----

.Array
[source,json]
----
{
  "field": [1, 2, 3]
}
----

->

----
field[0]=1
field[1]=2
field[2]=3
----

=== XML

Here is a sample XML file that can be imported by {app-name}:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<records>
    <trade>
        <isin>XYZ0001</isin>
        <quantity>5</quantity>
        <price>11.39</price>
        <customer>Customer1</customer>
    </trade>
    <trade>
        <isin>XYZ0002</isin>
        <quantity>2</quantity>
        <price>72.99</price>
        <customer>Customer2c</customer>
    </trade>
    <trade>
        <isin>XYZ0003</isin>
        <quantity>9</quantity>
        <price>99.99</price>
        <customer>Customer3</customer>
    </trade>
</records>
----

.XML import example
[source,shell]
----
include::{resources}/xml/import-hmset.txt[]
----


=== Redis

{app-name} can also import Redis data structure files in JSON or XML formats (see Export -> Redis to generate such files).

These files look like this:
[source,json]
----
[
 {"key":"string:615","ttl":-1,"value":"value:615","type":"STRING"},
 {"key":"hash:511","ttl":-1,"value":{"field1":"value511","field2":"value511"},"type":"HASH"},
 {"key":"list:1","ttl":-1,"value":["member:991","member:981"],"type":"LIST"}, 
 {"key":"set:2","ttl":-1,"value":["member:2","member:3"],"type":"SET"}, 
 {"key":"zset:0","ttl":-1,"value":[{"value":"member:1","score":1.0}],"type":"ZSET"},
 {"key":"stream:0","ttl":-1,"value":[{"stream":"stream:0","id":"1602190921109-0","body":{"field1":"value0","field2":"value0"}}],"type":"STREAM"}
]
----


.Redis JSON import example
[source,shell]
----
include::{resources}/json/import.txt[]
----

== Export

Use the `export` command to export data from Redis to files in CSV, fixed-width, JSON, or XML formats. These files can be gzip-compressed as well.

=== JSON

.Compressed JSON export example
[source,shell]
----
include::{resources}/json/export-gzip.txt[]
----

=== XML

.XML export example
[source,shell]
----
include::{resources}/xml/export.txt[]
----