[[_riot_redis]]
= RIOT Redis
:connector: riot-redis
:connector-title: RIOT Redis
:test-resources: ../../../../../connectors/riot-redis/src/test/resources

Most database migration tools available today are offline in nature. Migrating data from AWS ElastiCache to Redis Enterprise Cloud for example means backing up your Elasticache data to an AWS S3 bucket and importing it into Redis Enterprise Cloud using its UI.

{connector-title} is a migration tool that allows for live data migration between any Redis databases.

{connector-title} does not make use of the https://redis.io/commands/replicaof[REPLICAOF] command which is not always available (see https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/RestrictedCommands.html[ElastiCache restrictions]). Instead it implements client-side replication using DUMP and RESTORE:

image::replication.png[]

1. Key reader: initiates a SCAN and optionally calls SUBSCRIBE to listen for keyspace notifications (live replication).
2. Value reader: takes the keys and calls DUMP and TTL.
3. Key/Value writer: takes key/value/ttl tuples and calls RESTORE and EXPIRE.

include::getting-started.adoc[leveloffset=+1]

== Replicating

The `replicate` command reads data from a source Redis database and writes it to a target Redis database. The general usage is:

[subs=+quotes]
....
[green]#riot-redis# -h <src host> -p <src port> replicate -h <dest host> -p <dest port>
....

To show the full usage, run:

[subs="attributes,+quotes"]
....
[green]#{connector}# replicate --help
....

.Simple replication example
[source,bash]
----
include::{test-resources}/replicate[]
----

.Live replication example
[source,bash]
----
include::{test-resources}/replicate-live[]
----

=== Type-Based Replication

{connector-title} 2.8 introduced another type of replication that uses data structure-specific producers and consumers where each Redis data structure type has a corresponding pair of read/write commands:

[options="header",cols=",m,m",frame="none",grid="none"]
|=========================================================
|Type|Read|Write

|Hash|HGETALL|HSET
|List|LRANGE|RPUSH
|Set|SMEMBERS|SADD
|Sorted Set|ZRANGE|ZADD
|Stream|XRANGE|XADD
|String|GET|SET

|=========================================================

To select this replication mechanism pass `--type ds` option to the `replicate` command:

.Live type-based replication example
[source,bash]
----
include::{test-resources}/replicate-ds-live[]
----


WARNING: This replication strategy is more intensive in terms of CPU, memory, and network for the machines running {connector-title}. Adjust number of threads, batch, and queue sizes accordingly.

=== Verification

Once replication is complete (i.e. for snapshot replication when scan is complete, for live replication when no keyspace notification idle) {connector-title} will perform a verification step. This step iterates over keys in the source database and compares values and TTLs between source and target databases. The output looks like this:

----
>1,234 T2,345 ≠3,456 ⧗4,567 <5,678
----

* `>`: # keys only present in source database
* `T`: # mismatched data structure types
* `≠`: # mismatched values
* `⧗`: # keys with TTL delta greater than tolerance
* `<`: # keys only present in target database

== Architecture

{connector-title} follows a producer/consumer approach.

=== Producer

The producer is connected to the source Redis (e.g. ElastiCache) database and iterates over keys to be replicated by performing a SCAN and reading the corresponding values with DUMP. This is the snapshot part of the replication process.

If live replication is enabled the producer also subscribes to keyspace notifications to generate a continuous stream of keys and corresponding values.

TIP: Make sure the source Redis database has keyspace notifications enabled using `notify-keyspace-events = KA` in `redis.conf` or via CONFIG SET.

WARNING: The live replication mechanism does not guarantee data consistency. Redis sends keyspace notifications over pub/sub which does not provide	guaranteed delivery. It is possible that {connector-title} can miss some notifications in case of network failures for example.

Both snapshot and live producer processes make use of https://redis.io/topics/pipelining[pipelining] in order to read values in a batch fashion. Use the `--reader-batch` option to configure the number of values to be read in a single pipelined call. Each process can be multi-threaded using the `--reader-threads` option.

=== Consumer

The consumer is responsible for ingesting the keys and values generated by the producer and writing them to the target Redis database (e.g. Redis Enterprise Cloud). For each key/value pair it issues a RESTORE command.

The consumer process also makes use of https://redis.io/topics/pipelining[pipelining] in order to write values in a batch fashion. Use the `--batch` option to configure the number of values to be written in a single pipelined call.

Like the consumer the producer process can be multi-threaded, using the `--threads` option.
