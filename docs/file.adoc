= {app-name}
:app-name: RIOT File
:app: riot-file
:resources: ../connectors/file/src/test/resources
include::toc.adoc[]
include::github.adoc[]

*{app-name}* lets you import/export local or remote files in many formats like CSV, JSON, and XML.

== Getting Started

include::getting_started.adoc[]

== Importing

Use the `import` command to import data from files in CSV, fixed-width, JSON, and XML formats.

=== Usage

[source,shell]
----
❯ riot-file import --help
Usage: riot-file import [OPTIONS] FILE... [REDIS COMMAND]
Import file(s) into Redis
      FILE...                One ore more files or URLs
  -H, --help                 Show this help message and exit.
      --[no-]progress        Show progress bars. True by default.
      --threads=<int>        Thread count (default: 1).
  -b, --batch=<size>         Number of items in each batch (default: 50).
      --max=<count>          Max number of items to read.
      --skip-limit=<int>     Max number of failed items to skip before the transfer fails (default: 0).
      --encoding=<charset>   File encoding (default: UTF-8)
  -t, --type=<type>          File type: CSV, PSV, TSV, FW, JSON, XML
  -z, --gzip                 File is gzip compressed
      --fields=<names>...    Delimited/FW field names
  -h, --header               Delimited/FW first line contains field names
      --delimiter=<string>   Delimiter character
      --skip=<count>         Delimited/FW lines to skip at start
      --include=<index>...   Delimited/FW field indices to include (0-based)
      --ranges=<int>...      Fixed-width column ranges
      --quote=<char>         Escape character for delimited files (default: ")
      --cont=<string>        Line continuation string (default: \)
      --process=<f=exp>...   SpEL processors in the form: --process field1=" <expression>" field2="<expression>" …
      --var=<v=exp>...       Register a variable in the SpEL processor context
      --date=<string>        Processor date format (default: M/d/yy, h:mm a)
      --filter=<exp>...      Discard records using SpEL boolean expressions
      --regex=<f=exp>...     Extract named values from source field using regex
Amazon Simple Storage Service options
      --s3-access=<string>   Access key
      --s3-secret[=<string>] Secret key
      --s3-region=<string>   AWS region
Google Cloud Storage options
      --gcs-key-file=<file>  GCS private key (e.g. /usr/local/key.json)
      --gcs-project=<string> GCP project id
      --gcs-key=<string>     GCS Base64 encoded key
Redis commands:
  eval         Evaluate a Lua script with keys and arguments from input
  expire       Set timeouts on keys
  geoadd       Add members to a geo set
  hset, hmset  Set hashes from input
  lpush        Insert values at the head of a list
  noop         No operation: accepts input and does nothing
  rpush        Insert values at the tail of a list
  sadd         Add members to a set
  set          Set strings from input
  xadd         Append entries to a stream
  zadd         Add members with scores to a sorted set
----

=== Paths
Paths can include https://man7.org/linux/man-pages/man7/glob.7.html[wildcard patterns].

{app-name} will try to determine the file type from its extension (e.g. `.csv` or `.json`), but you can specify it explicity using the `--filetype` option. Gzipped files are supported and the extension before `.gz` is used (e.g. `myfile.json.gz` -> JSON type). 

.Examples
* `/path/file.csv`
* `/path/file-*.csv`
* `/path/file.json`
* `\http://data.com/file.csv`
* `\http://data.com/file.json.gz`

TIP: Use `-` to read from standard input.

For AWS S3 buckets you can specify access and secret keys as well as the region for the bucket.

`{app} import s3://my-bucket/path/file.json --s3-region us-west-1 --s3-access xxxxxx --s3-secret xxxxxx`

For Google Cloud Storage you can specify credentials and project id for the bucket:

`{app} import gs://my-bucket/path/file.json --gcs-key-file key.json --gcs-project-id my-gcp-project`

=== Formats

{app-name} supports delimited (CSV) and fixed-length (aka fixed-width) formats.

If the file has a header containing field names use the `--header` option. Otherwise specify the field names explicitly using the `--fields` option. 

==== Delimited

The default delimiter character is comma (`,`). It can be changed with the `--delimiter` option.

Let's consider this CSV file:

.https://raw.githubusercontent.com/nickhould/craft-beers-dataset/master/data/processed/beers.csv[beers.csv]
|=========
|   | abv   | ibu | id   | name        | style                   | brewery_id | ounces

| 0 | 0.05  |     | 1436 | Pub Beer    | Pale Lager     | 408        | 12.0

| 1 | 0.066 |     | 2265 | Devil's Cup | APA | 177        | 12.0

| ... | | | | | | |

|=========

The following command imports that CSV file into Redis as hashes using `beer` as the key prefix and `id` as primary key.

.CSV import example
[source,shell]
----
>
include::{resources}/import-csv[]
----

This creates hashes with keys `beer:1436`, `beer:2265`, ...

.CSV import to geo set
[source,shell]
----
include::{resources}/import-geoadd[]
----

==== Fixed-Length

These files have fixed-width fields. The width of each field must be defined using the `--ranges` option.

==== JSON

The expected format for JSON files is:

[source,json]
----
[
  {
    ...
  },
  {
    ...
  }
]
----

.JSON import example
[source,shell]
----
include::{resources}/import-json[]
----

JSON records are trees with potentially nested values that need to be flattened when the target is a Redis hash for example.

To that end, {app-name} uses a field naming convention to flatten JSON objects and arrays:

.Nested object
[source,json]
----
{
  "field":
    {
      "sub": "value"
    }
}
----

->

----
field.sub=value`
----

.Array
[source,json]
----
{
  "field": [1, 2, 3]
}
----

->

----
field[0]=1
field[1]=2
field[2]=3
----

==== XML

Here is a sample XML file that can be imported by {app-name}:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<records>
    <trade>
        <isin>XYZ0001</isin>
        <quantity>5</quantity>
        <price>11.39</price>
        <customer>Customer1</customer>
    </trade>
    <trade>
        <isin>XYZ0002</isin>
        <quantity>2</quantity>
        <price>72.99</price>
        <customer>Customer2c</customer>
    </trade>
    <trade>
        <isin>XYZ0003</isin>
        <quantity>9</quantity>
        <price>99.99</price>
        <customer>Customer3</customer>
    </trade>
</records>
----

.XML import example
[source,shell]
----
include::{resources}/import-xml[]
----

==== Redis Dumps

{app-name} can also import Redis data structure files in JSON or XML formats (see Export -> Redis to generate such files).

These files look like this:
[source,json]
----
[
 {"key":"string:615","ttl":-1,"value":"value:615","type":"STRING"},
 {"key":"hash:511","ttl":-1,"value":{"field1":"value511","field2":"value511"},"type":"HASH"},
 {"key":"list:1","ttl":-1,"value":["member:991","member:981"],"type":"LIST"},
 {"key":"set:2","ttl":-1,"value":["member:2","member:3"],"type":"SET"},
 {"key":"zset:0","ttl":-1,"value":[{"value":"member:1","score":1.0}],"type":"ZSET"},
 {"key":"stream:0","ttl":-1,"value":[{"stream":"stream:0","id":"1602190921109-0","body":{"field1":"value0","field2":"value0"}}],"type":"STREAM"}
]
----

=== Processing

include::processing.adoc[]

=== Redis Commands

include::redis-commands.adoc[]

== Exporting

Use the `export` command to export data from Redis to files in CSV, fixed-width, JSON, or XML formats. These files can be gzip-compressed as well.

.Compressed JSON export example
[source,shell]
----
include::{resources}/export-json-gz[]
----

.XML export example
[source,shell]
----
include::{resources}/export-xml[]
----