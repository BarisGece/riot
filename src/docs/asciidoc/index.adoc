= RIOT
:source-highlighter: highlightjs
:idprefix:
:idseparator: -
:toc: macro
:sectanchors:
:icons: font
:project-repo: Redislabs-Solution-Architects/riot
:repo-url: https://github.com/{project-repo}

----
█████╗ ██╗ █████╗██████╗
██╔═██╗██║██╔══██╚═██╔═╝
█████╔╝██║██║  ██║ ██║
██╔═██╗██║╚█████╔╝ ██║
╚═╝ ╚═╝╚═╝ ╚════╝  ╚═╝
Redis Input/Output Tool
----

toc::[]

== Architecture

RIOT reads records from a source (file, database, Redis, generator) and writes them to a target (file, database, Redis).

image::images/architecture.png[]

In most cases some processing needs to happen in order to adapt input records to the output.

For example records from  delimited files are string maps (key/value pairs where values are character strings) that look
pretty much exactly like Redis hashes.

However you still need to extract keys from those records, i.e. one or more fields should be used to construct the
corresponding Redis keys.

image::images/mapping.png[]

== Connectors

[#files]
=== Files

RIOT can import/export local or remote files in CSV, fixed-width, or JSON format with optional GZIP compression:

* `/myfolder/myfile.csv`
* `/myfolder/myfile.json.gz`
* `\https://example.com/path/dataset.csv`
* `s3://mybucket/myfolder/myfile.json`

For AWS S3 you can specify access and secret keys as well as the region for the bucket.

TIP: Use `-` to import/export from/to standard input/output.

Specify the file type using the `--filetype` option. If not RIOT will try to determine it from the file extension (e.g. `.csv` or `.json`).

==== Delimited

* Delimiter character

The default delimiter character is comma (`,`). It can be changed with the `--delimiter` option.

* Field names

To specify field names use the `--fields` option (see xref:import-csv-geo[]).

If the file has a header containing field names, use the `--header` option to have RIOT obtain the fields from that header.

* Importing

Let's use this CSV file: https://raw.githubusercontent.com/nickhould/craft-beers-dataset/master/data/processed/beers.csv

|=========
|   | abv   | ibu | id   | name        | style                   | brewery_id | ounces

| 0 | 0.05  |     | 1436 | Pub Beer    | Pale Lager     | 408        | 12.0

| 1 | 0.066 |     | 2265 | Devil's Cup | APA | 177        | 12.0

|=========

The following command imports the CSV data into Redis hashes with `beer` as the key prefix and `id` as the primary key, which means that the keys will be `beer:1436`, `beer:2265`, ...
.Import CSV to Hashes
[source,shell]
----
include::{commandsdir}/import-csv-hash.txt[]
----

.Import CSV into RediSearch index
[source,shell]
----
include::{commandsdir}/import-csv-search.txt[]
----

[#import-csv-geo]
.Import CSV to a Geo set
[source,shell]
----
include::{commandsdir}/import-csv-geo.txt[]
----

.Import CSV into RediSearch geo
[source,shell]
----
include::{commandsdir}/import-csv-processor-search-geo.txt[]
----

.Export to CSV
[source,shell]
----
include::{commandsdir}/export-csv.txt[]
----

==== JSON

The expected format is:
----
[
  {
     // JSON object
  },
  {
     // JSON object
  }
]
----

JSON records are trees with potentially nested values that need to be flattened when stored in a Redis hash.

To that end, RIOT uses a field naming convention to flatten JSON objects and arrays:

* `{ "field": { "sub": "value" } }`
-> `field.sub=value`
* `{ "field": [1, 2, 3] }`
-> `field[0]=1 field[1]=2 field[2]=3`


.Import JSON
[source,shell]
----
include::{commandsdir}/import-json-hash.txt[]
----

.Export JSON
[source,shell]
----
include::{commandsdir}/export-json.txt[]
----

.Export compressed JSON
[source,shell]
----
include::{commandsdir}/export-json_gz.txt[]
----


[#db]
=== Databases

RIOT can connect to SQL databases through JDBC. Install the appropriate JDBC driver
under the `lib` directory and modify the RIOT `CLASSPATH` accordingly:

* *nix: `bin/riot` -> `CLASSPATH=$APP_HOME/lib/myjdbc.jar:$APP_HOME/lib/…`

* Windows: `bin\riot.bat` -> `set CLASSPATH=%APP_HOME%\lib\myjdbc.jar;%APP_HOME%\lib\…`

For reference here are links to common database systems and related JDBC driver documentation:

* https://docs.oracle.com/cd/E11882_01/appdev.112/e13995/oracle/jdbc/OracleDriver.html[Oracle]
+
`jdbc:oracle:thin:@myhost:1521:orcl`

* https://www.ibm.com/support/knowledgecenter/en/SSEPEK_10.0.0/java/src/tpc/imjcc_r0052342.html[IBM Db2]
+
`jdbc:db2://host:port/database`

* https://docs.microsoft.com/en-us/sql/connect/jdbc/building-the-connection-url?view=sql-server-2017[MS SQL Server]
+
`jdbc:sqlserver://[serverName[\instanceName][:portNumber]][;property=value[;property=value]]`

* https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-jdbc-url-format.html[MySQL]
+
`jdbc:mysql://[host]:[port][/database][?properties]`

* https://www.postgresql.org/docs/7.4/jdbc-use.html[PostgreSQL]
+
`jdbc:postgresql://host:port/database`


* https://www.sqlitetutorial.net/sqlite-java/sqlite-jdbc-driver/[SQLite]
+
`jdbc:sqlite:sqlite_database_file_path`


.Import from a database
[source,shell]
----
include::{commandsdir}/import-db.txt[]
----

.Export to a database
[source,shell]
----
include::{commandsdir}/export-db.txt[]
----

[#gen]
=== Generators

RIOT can be used to create random data in Redis with 2 different generators.

==== Simple

The simple generator produces the following fields:
* `index`: monotonous integer sequence
* `partition`: index of the partition (thread) generating the data, e.g. if you have 8 threads generating data each will have a different partition index between 0 and 7
* configurable fixed-sized fields using `--field <name=size>` options

[source,shell]
----
include::{commandsdir}/gen-simple.txt[]
----

==== Faker

The Faker generator relies on the https://github.com/DiUS/java-faker[Faker] library.

Supported data types are described <<faker#,here>>.

.Faker Hashes
[source,shell]
----
include::{commandsdir}/gen-faker-hash.txt[]
----

.Faker Sets
[source,shell]
----
include::{commandsdir}/gen-faker-set.txt[]
----

.RediSearch with introspection
[source,shell]
----
include::{commandsdir}/gen-faker-index-introspection.txt[]
----

[#redis]
=== Redis

The Redis connector allows for replicating data between two Redis databases using scan and optionally keyspace notifications (`--listen`).

.Live replication from `localhost:16379` to `localhost:16380`
[source,shell]
----
include::{commandsdir}/replicate-live.txt[]
----


== Processors

RIOT can process records with field expressions.

You can specify field expressions to process key/value pairs using the https://docs.spring.io/spring/docs/current/spring-framework-reference/core.html#expressions[Spring Expression Language] (SpEL): `field1=<exp>`, `field2=<exp>`, ...

The input record is accessed through its field names (e.g. `field3=field1+field2`).

The processor also exposes the following variables that can be called with the `#` prefix:

* `redis`: Redis connection to issue any command, e.g. `name=#redis.hgetall('person1').lastName`
* `date`: date parser/formatter, e.g. `epoch=#date.parse(mydate).getTime()`
* `index`: sequence number e.g. `id=#index`

[source,shell]
----
include::{commandsdir}/import-csv-processor-hash-dateformat.txt[]
----

== Load Testing

=== Metrics
Use the `--metrics` option to show latency metrics when using the Lettuce driver:
[source,shell]
----
riot --metrics …
----
[source,plaintext]
----
{[local:any -> localhost/127.0.0.1:6379, commandType=SET]=[count=401, timeUnit=MICROSECONDS, firstResponse=[min=116, max=7274, percentiles={50.0=197, 90.0=458, 95.0=606, 99.0=1081, 99.9=7274}], completion=[min=128, max=8519, percentiles={50.0=219, 90.0=489, 95.0=634, 99.0=1122, 99.9=8519}]]}
{[local:any -> localhost/127.0.0.1:6379, commandType=SET]=[count=1403, timeUnit=MICROSECONDS, firstResponse=[min=48, max=704, percentiles={50.0=99, 90.0=156, 95.0=183, 99.0=280, 99.9=573}], completion=[min=49, max=909, percentiles={50.0=108, 90.0=171, 95.0=205, 99.0=317, 99.9=581}]]}
{[local:any -> localhost/127.0.0.1:6379, commandType=SET]=[count=1684, timeUnit=MICROSECONDS, firstResponse=[min=56, max=516, percentiles={50.0=80, 90.0=124, 95.0=142, 99.0=183, 99.9=391}], completion=[min=58, max=520, percentiles={50.0=82, 90.0=127, 95.0=146, 99.0=188, 99.9=403}]]}
----

=== Using Redis Enterprise
==== Strings
[source,shell]
----
❯ riot -s redis-12001.redislabs.com:12001 --max-total 96 gen --batch 5000 --threads 96 --max 100000000 --command set --keyspace hash --keys index --value index
----
image::images/rs-strings.png[]

==== Streams
[source,shell]
----
❯ riot -s redis-12001.internal.jrx.demo.redislabs.com:12001 --pool-max-total 96 gen --batch 5000 --threads 96 --max 100000000 --command xadd --keyspace stream --keys partition
----
image::images/rs-streams.png[]